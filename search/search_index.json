{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"additional-guides/adding-python-packages-via-virtual-environment/","title":"Adding python packages via virtual environment","text":"<p>To enhance the functionality of a containerized environment, you can add additional Python packages using a virtual environment. This guide outlines the steps to create and utilize a virtual environment within your container.</p> <p>Begin by creating a virtual environment in your directory. This allows you to install packages that your container instance can access.</p> <pre><code>python3 -m venv my-virtual-env\n</code></pre> <p>Launch a shell session within your container using Singularity (in this case <code>tensorflow_24.03-tf2-py3.sif</code>).</p> <pre><code>srun --pty singularity shell /ceph/container/tensorflow_24.03-tf2-py3.sif\n</code></pre> <pre><code>srun --pty singularity shell tensorflow_24.03-tf2-py3.sif\n</code></pre> <p>Once inside the container's shell, activate the virtual environment you just created.</p> <pre><code>source my-virtual-env/bin/activate\n</code></pre> <p>With the virtual environment activated, install the Python packages you need. For example, to install <code>numpy</code>, <code>pandas</code>, and <code>matplotlib</code>:</p> <pre><code>pip install numpy pandas matplotlib\n</code></pre> <p>This command will download and install the specified packages into your virtual environment.</p> <p>To confirm that the packages were successfully installed and are accessible within the container, you can check their versions or run basic scripts:</p> <pre><code>python3 -c \"import matplotlib; print(matplotlib.__version__)\"\n</code></pre> <p>Remember that you must always activate the virtual environment (<code>source my-virtual-env/bin/activate</code>) within your container's shell before using the installed packages. This ensures that Python knows where to find the packages and dependencies.</p>"},{"location":"additional-guides/building-your-own-container-image/","title":"Building your own container image","text":"<p>It is possible to define and build your own container images with Singularity. Lets try creating a Singularity container image with Python and pip installed. </p> <p>Another way to build containers using Cotainr</p> <p>You also have the option to use a software called cotainr to build containers. We have a guide on how to install a Conda environment with Cotainr here.</p> <p>First we need to create a Singularity definition file (<code>.def</code>). This definition file is a blueprint for how Singularity should build the container image. It includes information about the base OS to build, which software to install and several other options.</p> <p>Lets create an empty text file by using the <code>nano</code> command:</p> <pre><code>nano\n</code></pre> <p>Now we can enter the blueprint needed to install our application:</p> <pre><code>Bootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    # This section is where you install additional packages or software\n    # Update package list and install the latest Python and pip version\n    apt-get update\n    apt-get install -y python3 python3-pip\n    pip install numpy pandas scikit-learn matplotlib\n\n%test\n    # Define tests to run after the container is built\n    python3 --version\n</code></pre> <p>In this example we will use <code>docker</code> to pull <code>ubuntu:20.04</code> as the base OS of our container image. </p> <p>In the next section,<code>%post</code>, we can define commands that will be executed after the base OS has been installed. In this example, we will update the container and install <code>python3</code> and <code>pip</code> along with <code>numpy pandas scikit-learn matplotlib</code> packages. </p> <p>After that we can define commands to run after the container is built in the <code>%test</code> section. Lets try with <code>python3 --version</code>.</p> <p>You can find more options to use in definition file in the Singularity definition file documentation.</p> <p>To save the file press <code>CTRL + O</code> and enter a filename ending with <code>.def</code> and hit <code>ENTER</code>. In this example, lets call it <code>python3.def</code>.</p>"},{"location":"additional-guides/building-your-own-container-image/#get-access-token-from-sylabs","title":"Get access token from Sylabs","text":"<p>Before you can build the container, you need to get an access token from Sylabs in order to authenticate the build of the container. Head over to https://cloud.sylabs.io/ and Sign up for a new account (its free). Once you are logged it, then hover over your username in the top, and choose Access Tokens</p> <p></p> <p>Now, enter a name, in this case \"mytoken\" and press \"Create Access Token\". An access token is created, that you can use for 1 month before it expires. </p> <p></p> <p>Now go back to the terminal and enter the following command to verify your access token:</p> <pre><code>srun singularity remote login\n</code></pre> <p>When prompted, paste the token you just copied.</p> <pre><code>Generate an access token at https://cloud.sylabs.io/auth/tokens, and paste it here.\nToken entered will be hidden for security.\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJodHRwczovL2F1dGguc3lsYWJzLmlvL3Rva2VuIiwic3ViIjoiNjY3YThmMTJmMGVkNGQxMzdhYTA1NzMwIiwiZXhwIjoxNzIxOTA0MzE4LCJpYXQiOjE3MTkzMTIzMTgsImp0aSI6IjY2N2E5ZmJlMTRjNTI5MTY5Zjk4OGQwYyJ9.DseTflfB6_mT_9HQpX6tUetfdOR7-_QzVdJOu-reO6OY6rFYJ1ZU2acbkPJ2sLqUSGYfTp8bAOrvawZKJQ1hIGkFx3qGjK1s_sFx18dboN0zjFZPbsk41m6Vmu3u5d1tWzfCDn2GgGBgdeJ411M6ECvfAFCV5In3G5abZ44KyY_N1_ziPOYTmLCbtGEbagxBFIBIyGVhMtyFNdaPfVANko8BtsCAhi3_dW0jsT4EzMBpf3afEhdbjIPP5T_gWuTzxqY-VEQQZVYKr-TA9rfv-CPS_kzBK8AQ3kZThryUTi818Xxolr2UGjjph-m4aVN9sLNfSqJu3PQx1UdxBsyoPA\nAccess Token:\nINFO:    Access Token Verified!\n...\n</code></pre> <p>This You can now build container images from definition files using <code>--remote</code>. Lets build a container image from <code>python3.def</code> file:</p> <pre><code>srun singularity build --remote python3.sif python3.def\n</code></pre> <p>After some time you should  see the <code>Python X.X.X</code> version be printed in the terminal, and you should now have a <code>python3.sif</code> container image ready to run.</p> <p>Lets for example print the matplotlib version:</p> <pre><code>srun singularity exec python3.sif python3 -c \"import matplotlib; print('Matplotlib version:', matplotlib.__version__)\"\n</code></pre> <p>You can find more information about building containers from Singularity definition files here.</p>"},{"location":"additional-guides/cancelling-jobs/","title":"Cancelling jobs","text":"<p>There are several scenarios where you might need to cancel jobs, such as when a job is stuck, running longer than expected, or you realize that the job parameters were set incorrectly. Here\u2019s a guide on how to cancel jobs with Slurm.</p>"},{"location":"additional-guides/cancelling-jobs/#checking-job-status","title":"Checking Job Status","text":"<p>Before cancelling a job, it\u2019s often useful to check its current status or job ID. You can list your currently running or queued jobs using the squeue command:</p> <pre><code>squeue --me\n</code></pre>"},{"location":"additional-guides/cancelling-jobs/#cancelling-a-single-job","title":"Cancelling a Single Job","text":"<p>To cancel a specific job, use the <code>scancel</code> command followed by the job ID. For example, if your job ID is <code>12345</code>, you can cancel it by running:</p> <pre><code>scancel 12345\n</code></pre>"},{"location":"additional-guides/cancelling-jobs/#cancelling-multiple-jobs","title":"Cancelling Multiple Jobs","text":"<p>If you need to cancel all your jobs, you can cancel all jobs belonging to your user by using:</p> <pre><code>scancel --user=$USER\n</code></pre> <p>This command is particularly useful if you have submitted a batch of jobs and need to cancel them all simultaneously.</p>"},{"location":"additional-guides/checking-gpu-usage/","title":"Checking GPU usage","text":"<p>Monitoring GPU usage is a good practice for optimizing the performance of your jobs running, particularly if you intend to utilize multiple GPUs and verify their usage. This guide will provide step-by-step instructions on how to monitor GPU usage using the <code>nvidia-smi</code> tool.</p>"},{"location":"additional-guides/checking-gpu-usage/#start-a-job-with-gpu-allocation","title":"Start a job with GPU allocation","text":"First, submit a job using <code>srun</code> or <code>sbatch</code> with one GPU or more allocated and execute some code inside a Singularity container. In this example we will use the <code>pytorch_24.03-py3.sif</code> container image from <code>/ceph/container</code> directory and a PyTorch benchmark script <code>torch_bm.py</code> from <code>/ceph/course/claaudia/docs</code> directory:      <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/pytorch_24.03-py3.sif python3 torch_bm.py\n</code></pre>      First, submit a job using <code>srun</code> or <code>sbatch</code> with one GPU or more allocated and execute some code inside a Singularity container. In this example we will use <code>pytorch_24.03-py3.sif</code> container image and a PyTorch benchmark script <code>torch_bm.py</code>:      <pre><code>srun --gres=gpu:1 singularity exec --nv pytorch_24.03-py3.sif python3 torch_bm.py\n</code></pre> <p>This script is NOT optimized for utilizing multiple GPUs, so in this example we will only allocate 1 GPU. Here is an example of a PyTorch script that can handle multiple GPUs.</p>"},{"location":"additional-guides/checking-gpu-usage/#check-job-id","title":"Check job id","text":"<p>Open another terminal session, and check the status of your jobs using <code>squeue --me</code> to find the job ID of the job you just submitted.</p> <pre><code>squeue --me\n</code></pre>"},{"location":"additional-guides/checking-gpu-usage/#connect-to-running-job-interactively","title":"Connect to running job interactively","text":"<p>Once you have identified the job ID (let's assume it's <code>1978</code> in this example), connect to the running job interactively using the following command to start a new shell.</p> <pre><code>srun --jobid 1978 --interactive --pty /bin/bash\n</code></pre>"},{"location":"additional-guides/checking-gpu-usage/#monitor-gpu-usage","title":"Monitor GPU usage","text":"<p>Inside the interactive session of your job, start monitoring GPU usage using <code>nvidia-smi</code> with watch to update the output every second.</p> <pre><code>watch -n1 nvidia-smi\n</code></pre> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L4                      Off |   00000000:01:00.0 Off |                    0 |\n| N/A   44C    P0             36W /   72W |     245MiB /  23034MiB |     90%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA L4                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA L4                      Off |   00000000:41:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   3  NVIDIA L4                      Off |   00000000:61:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n...\n</code></pre> <p>The most important parameter to notice here is the <code>GPU-Util</code> metric. Here, you can see that the first GPU is operating at 90% GPU utilization. This indicates excellent utilization of the GPU.</p> <p>High Utilization (70-100%)</p> <p>For many GPU-accelerated applications like deep learning training or scientific simulations, a high GPU utilization (often around 70-100%) during compute-intensive tasks is considered good. It indicates that the GPU is efficiently processing tasks without significant idle time.</p> <p>Low to Moderate Utilization (10-40%)</p> <p>In some cases, especially when the workload is less intensive or the application is idle waiting for data or other resources, the GPU utilization might be lower (e.g., 10-40%). This doesn't necessarily mean the GPU is underutilized or performing poorly; it could indicate a natural variation in workload or efficient scheduling of tasks.</p>"},{"location":"additional-guides/checking-the-queue/","title":"Checking the queue","text":"<p>When using the cluster, you typically wish to see an overview of what is currently in the queue. For example to see how many jobs might be waiting ahead of you or to get an overview of your own jobs.</p> <p>The command <code>squeue</code> can be used to get a general overview:</p> <pre><code>squeue\n\nJOBID   PARTITION       NAME      USER    ST      TIME    NODES   NODELIST(REASON)\n42            gpu   interact  xxxxxxxx     R   6:45:14        1        ailab-l4-01\n</code></pre> <pre><code>squeue\n\nJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n31623     batch     DRSC xxxxxxxx  R    6:45:14      1 i256-a10-10\n31693     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31694     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31695     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31696     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31502 prioritiz runQHGK. zzzzzzzz PD       0:00      1 (Dependency)\n31504 prioritiz runQHGK. zzzzzzzz PD       0:00      1 (Dependency)\n</code></pre> <ol> <li><code>JOBID</code> shows the <code>ID</code> number of each job in queue.</li> <li><code>PARTITION</code> shows which partition each job is running in.</li> <li><code>NAME</code> is the name of the job which can be specified by the user creating it.</li> <li><code>USER</code> is the username of the user who created the job.</li> <li><code>ST</code> is the current state of each job; for example <code>R</code> means a job is running and <code>PD</code> means pending. There are other states as well - see <code>man squeue</code> for more details (under <code>JOB STATE CODES</code>).</li> <li><code>TIME</code> shows how long each job has been running.</li> <li><code>NODES</code> shows how many nodes are involved in each job allocation.</li> <li><code>NODELIST</code> shows which node(s) each job is running on, or alternatively, why it is not running yet.</li> </ol> <p>Showing your own jobs only:</p> <pre><code>squeue --me\n</code></pre> <p><code>squeue</code> can show many other details about jobs as well. Run <code>man squeue</code> to see detailed documentation on how to do this.</p>"},{"location":"additional-guides/checking-the-status-of-compute-nodes/","title":"Checking the status of compute nodes","text":"<p>It is often desirable to monitor the resource status of the compute nodes when you wish to run a job. </p> <p>The <code>sinfo</code> command shows basic information about partitions in the queue system and what the states of nodes in these partitions are.</p> <pre><code>sinfo\n\nPARTITION       AVAIL      TIMELIMIT      NODES      STATE             NODELIST\nl4*                up       12:00:00         11       idle     ailab-l4-[01-11]\nvmware             up          10:00          4       idle        vmware[01-04]\n</code></pre> <pre><code>sinfo\n\nPARTITION   AVAIL  TIMELIMIT  NODES  STATE NODELIST\nbatch*         up   12:00:00      1    mix nv-ai-04\nbatch*         up   12:00:00      8   idle a256-t4-[01-02],i256-a10-06,i256-a40-[01-02]...\nprioritized    up 6-00:00:00      8   idle a256-t4-[01-02],i256-a10-06,i256-a40-[01-02]...\n</code></pre> <ol> <li><code>PARTITION</code> can be understood as distinct categories or groups of compute nodes, essentially serving as separate queues for jobs.</li> <li><code>AVAIL</code> shows the availability of the partition where <code>up</code> is normal, working state where you can submit jobs to it.</li> <li><code>TIMELIMIT</code> shows the time limit imposed by each partition in <code>HH:MM:SS</code> format.</li> <li><code>NODES</code> shows how many nodes are in the shown state in the specific partition.</li> <li><code>STATE</code> shows which state the listed nodes are in: <code>mix</code> means that the nodes are partially full - some jobs are running on them and they still have available resources; <code>idle</code> means that they are completely vacant and have all resources available; <code>allocated</code> means that they are completely occupied. Many other states are possible, most of which mean that something is wrong.</li> <li><code>NODELIST</code> shows the specific compute nodes that is affected by the job.</li> </ol> <p>You can also use the command <code>scontrol show node</code> or <code>scontrol show node &lt;node name&gt;</code> to show details about all nodes or a specific node, respectively.</p> <pre><code>scontrol show node ailab-l4-04\n\nNodeName=ailab-l4-04 Arch=x86_64 CoresPerSocket=32\nCPUAlloc=0 CPUTot=128 CPULoad=2.00\nAvailableFeatures=(null)\nActiveFeatures=(null)\nGres=gpu:l4:8(S:0-1)\n...\n</code></pre> <pre><code>scontrol show node a256-t4-01\n\nNodeName=a256-t4-01 Arch=x86_64 CoresPerSocket=16 \nCPUAlloc=12 CPUTot=64 CPULoad=0.50\nAvailableFeatures=(null)\nActiveFeatures=(null)\nGres=gpu:t4:6\n...\n</code></pre> <p>The two commands <code>sinfo</code> and <code>scontrol show node</code> provide information which is either too little or way too much detail in most situations. As an alternative, we provide the tool <code>nodesummary</code> to show a hopefully more intuitive overview of the used/available resources.</p> <pre><code>nodesummary\n</code></pre> <p></p>"},{"location":"additional-guides/checkpointing/","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. This guide outlines how to implement and use checkpointing effectively within your jobs using different applications.</p> <p>Why checkpointing matters</p> <p> <p>Job Time Limits:On AI-LAB, jobs are restricted to a maximum runtime of 12 hours. Checkpointing allows you to save your model's progress periodically, ensuring that even if your job is terminated due to time limits, you can restart training from the last checkpoint rather than starting over.</p> </p> <p>Service Windows: There are times when the platform undergoes maintenance or updates, during which jobs cannot be run. Checkpointing enables you to pause training during these service windows and resume later without losing progress.</p> <p>Platform Errors: Platform errors can also sometimes occur, leading to job cancellations. Checkpointing mitigates this risk by saving your model's state at regular intervals, so you can recover and continue training from the point of interruption.</p>"},{"location":"additional-guides/checkpointing/#python-data-checkpointing","title":"Python data checkpointing","text":"<p>The following Python script demonstrates a basic checkpointing mechanism using the standard Python module pickle to periodically save the data of a process to a file.</p> <p><pre><code>import pickle\nimport os\n\ndef save_checkpoint(data, filename):\n    \"\"\"Save the checkpoint data to a file.\"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n\ndef load_checkpoint(filename):\n    \"\"\"Load the checkpoint data from a file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n# Check if there is a checkpoint file\nif os.path.exists('checkpoint.pkl'):\n    # If there is, load the checkpoint\n    data = load_checkpoint('checkpoint.pkl')\n    print(\"Resuming from checkpoint:\")\nelse:\n    # If there isn't, initialize data\n    data = {'counter': 0}\n\ntry:\n    # Simulate some long-running process\n    while True:\n        data['counter'] += 1\n        print(\"Current counter value:\", data['counter'])\n        # Save checkpoint every 5 iterations\n        if data['counter'] % 5 == 0:\n            save_checkpoint(data, 'checkpoint.pkl')\n        # Simulate some work\n        # Replace this with your actual process\n        import time\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    # Save checkpoint if the process is interrupted\n    save_checkpoint(data, 'checkpoint.pkl')\n    print(\"\\nCheckpoint saved. Exiting...\")\n</code></pre> </p>"},{"location":"additional-guides/checkpointing/#breakdown-of-the-key-components","title":"Breakdown of the key components:","text":"<p>First, the script checks if a checkpoint file named <code>checkpoint.pkl</code> exists using <code>os.path.exists()</code>. If the file exists, it loads the checkpoint data using <code>load_checkpoint</code> function and assigns it to data. If not, it initializes data with a dictionary containing a single key <code>counter</code> initialized to 0. </p> <p>Then, it enters an infinite loop (simulating a long-running process), where it increments the <code>counter</code> key of the data dictionary, prints the current counter value, and simulates some work (in this case, a 1-second delay using <code>time.sleep(1)</code>).</p> <p>Every 5 iterations (<code>if data['counter'] % 5 == 0)</code>, it saves the checkpoint by calling <code>save_checkpoint</code>. If the process is interrupted by a keyboard interrupt (Ctrl+C), it saves the current checkpoint and prints a message before exiting.</p>"},{"location":"additional-guides/checkpointing/#tensorflow-model-checkpointing","title":"TensorFlow model checkpointing","text":"<p>TensorFlow provides native support for checkpointing during model training, allowing you to save the model's weights at specific intervals. More information about TensorFlow checkpointing can be found here</p> <p>The following code example demonstrates training of a simple neural network model using TensorFlow and Keras on the MNIST dataset. However, the primary focus is on the marked lines indicating checkpointing implementation, using the <code>ModelCheckpoint</code> callback. </p> <pre><code>    import os\n    import sys\n    import os.path\n    import tensorflow as tf\n    from tensorflow import keras\n\n    #####Get an example dataset - we'll use the MNIST dataset first 1000 examples:\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\n    train_labels = train_labels[:5000]\n    test_labels = test_labels[:5000]\n\n    train_images = train_images[:5000].reshape(-1, 28 * 28) / 255.0\n    test_images = test_images[:5000].reshape(-1, 28 * 28) / 255.0\n\n    ##epoch number of steps for each job:\n    epoch_steps=20\n\n    ####Define a simple sequential model:\n    def create_model():\n        model = tf.keras.models.Sequential([\n            keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(10)\n        ])\n\n        model.compile(optimizer='adam',\n                        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                        metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n        return model\n\n\n    # Create a new model instance\n    model = create_model()\n\n    # Include the epoch in the file name (uses `str.format`)\n    checkpoint_path = \"checkpoints/{epoch:d}.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights every epoch (period=1)\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, \n        verbose=1, \n        save_weights_only=True,\n        period=1)\n\n    # Check if there are existing checkpoints\n    if os.path.exists(checkpoint_dir):\n        # If there are existing checkpoints, load the latest one\n        latest = tf.train.latest_checkpoint(checkpoint_dir)\n        # Load the previously saved weights, if there are any:\n        model.load_weights(latest)\n\n        # Re-evaluate the model\n        loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n        print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n\n        # Get the step number from the latest checkpoint\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n        step = int(os.path.basename(ckpt.model_checkpoint_path).split('.')[0])\n        print('Continuing calculation from epoch step:' + str(step)) \n        # Set the initial epoch to the last recovered epoch\n        initialEpoch=step\n    else:\n        initialEpoch=0\n        # Save the weights for the initial epoch\n        model.save_weights(checkpoint_path.format(epoch=0))\n\n    # Train the model with the new callback\n    model.fit(train_images, \n            train_labels,\n            epochs=epoch_steps, \n            initial_epoch=initialEpoch,\n            callbacks=[cp_callback],\n            validation_data=(test_images,test_labels),\n            verbose=1)\n</code></pre> <p></p>"},{"location":"additional-guides/checkpointing/#breakdown-of-the-key-components_1","title":"Breakdown of the key components:","text":"<p><code>checkpoint_path</code>: Specify the path where checkpoints will be saved. You can include dynamic elements such as epoch number in the file name to differentiate between checkpoints, like <code>checkpoints/{epoch:d}.ckpt</code></p> <p><code>cp_callback</code>: Create a ModelCheckpoint callback, which will save the model's weights at specified intervals during training. You can customize various parameters such as the file path, verbosity, and whether to save only the weights or the entire model.</p> <p><code>model.load_weights(latest)</code>: Before starting training, check if there are existing checkpoints. If so, load the latest one to resume training from the last saved state. This ensures continuity in training even if interrupted.</p>"},{"location":"additional-guides/checkpointing/#pytorch-model-checkpointing","title":"PyTorch model checkpointing","text":"<p>Checkpointing in PyTorch is a crucial technique used to save the state of your model and optimizer at various points, enabling you to resume training from a specific epoch in case of interruptions or to fine-tune models from previously saved states. More information about PyTorch checkpointing can be found here</p> <p>This following script demonstrates a simple feedforward neural network using PyTorch. However, the primary focus is on the marked lines indicating checkpointing implementation.</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Load MNIST dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('data', train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n    batch_size=64, shuffle=True)\n\n# Define the model\nmodel = SimpleNN()\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# Checkpoint directory\ncheckpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n##epoch number of steps\nepoch_steps = 20\n\n# Check if there are existing checkpoints\nif os.listdir(checkpoint_dir):\n    # If there are existing checkpoints, load the latest one\n    latest_checkpoint = max([int(file.split('.')[0]) for file in os.listdir(checkpoint_dir)])\n    checkpoint = torch.load(os.path.join(checkpoint_dir, f'{latest_checkpoint}.pt'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = latest_checkpoint + 1\nelse:\n    start_epoch = 0\n\n# Training loop\nfor epoch in range(start_epoch, epoch_steps):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.view(data.size(0), -1)\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}: Loss {loss.item()}')\n\n    # Save checkpoint every epoch\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n    }, os.path.join(checkpoint_dir, f'{epoch}.pt'))\n</code></pre> <p></p>"},{"location":"additional-guides/checkpointing/#breakdown-of-the-key-components_2","title":"Breakdown of the key components:","text":"<p>Checkpoint Directory Setup (line 39-41): Creating a directory for storing checkpoints.</p> <p>Checking for Existing Checkpoints (line 46-55): Checking for existing checkpoints and loading the latest one if available.</p> <p>Saving Checkpoints (line 69-75): Saving the model's state, optimizer's state, and current loss at the end of each epoch to a uniquely named file based on the epoch number.</p>"},{"location":"additional-guides/cpu-gpu-and-memory-allocation/","title":"CPU, GPU, and memory allocation","text":"<p>To effectively run jobs, it's important to understand the hardware configuration and set appropriate parameters for resource allocation. Here\u2019s a detailed guide on setting Slurm parameters based on the specified hardware on the platform:</p>"},{"location":"additional-guides/cpu-gpu-and-memory-allocation/#memory-per-job","title":"Memory per job","text":"<code>--mem</code> specifies the memory allocated to the job. Maximum value is 60 GB per GPU. Example:      <pre><code>srun --mem=60G singularity exec --nv /ceph/container/tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <code>--mem</code> specifies the memory allocated to the job. Example:      <pre><code>srun --mem=60G singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre>"},{"location":"additional-guides/cpu-gpu-and-memory-allocation/#cpus-per-task","title":"CPUs per task","text":"<code>--cpus-per-task</code> specifies the number of CPUs allocated to each task. Maximum value is 15 CPUs per GPU. Example:      <pre><code>srun --cpus-per-task=15 singularity exec --nv /ceph/container/tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <p>There is actually 16 CPUs per GPU available, but using a maximum of 15 CPUs per GPU, leaves 1 CPU free per GPU for system overhead and non-GPU tasks, which helps in maintaining overall system stability and performance.</p> <code>--cpus-per-task</code> specifies the number of CPUs allocated to each task. Example:      <pre><code>srun --cpus-per-task=15 singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre>"},{"location":"additional-guides/cpu-gpu-and-memory-allocation/#gpus-per-job","title":"GPUs per job","text":"<code>--gres=gpu</code> specifies the number of GPUs required for the jobs. Maximum value is 8 GPUs per job. Example:      <pre><code>run --gres=gpu:4 singularity exec --nv /ceph/container/tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <code>--gres=gpu</code> specifies the number of GPUs required for the jobs. Example:      <pre><code>srun --gres=gpu:4 singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <p>Request only the number of GPUs your job can effectively utilize. Over-requesting can lead to resource underutilization and longer queue times. Some applications may need adjustments to scale effectively across multiple GPUs. Here is an example of a PyTorch script that can handle multiple GPUs. </p> <p>Monitor GPU usage</p> <p>You can use the NVIDIA GPU monitoring command <code>nvidia-smi</code> to output GPU usage information. Learn how to use it in this guide.</p>"},{"location":"additional-guides/cpu-gpu-and-memory-allocation/#number-of-tasks-to-be-run","title":"Number of tasks to be run","text":"<p><code>--ntasks</code> specifies the number of tasks to be run. Each task typically corresponds to an independent execution of your program or script. If your job can be parallelized across multiple tasks, set the number of tasks to e.g. <code>--ntasks=4</code> for running 4 parallel tasks. Each task gets its allocation of resources (CPU, memory, etc.) based on other parameters like <code>--cpus-per-task</code>, <code>--mem</code>, and <code>--gres=gpu</code>.</p>"},{"location":"additional-guides/creating-a-conda-environment/","title":"Creating a conda environment","text":"<p>Creating a conda environment in a container may be easily done using cotainr. </p> <p>About cotainr</p> <p>cotainr is a tool developed by DeiC to ease building of Singularity containers. It can be used to build custom containers with additional software installable by Conda and Pip. This means it is primarily for adding Python packages to a container. It works from a base container image that you specify and then build additional Anaconda and pip packages which you supply as a conda environment specification.</p>    Cotainr is included in the <code>/ceph/container</code> directory. To check the current version, enter <code>ls /ceph/container</code>. Currently, the version used in this guide is <code>cotainr-2023.11.0</code>.    You can access cotainr by using the path <code>/ceph/container/cotainr-2023.11.0/bin/cotainr</code>. But first we will create a conda environment file, <code>conda_env.yml</code> that contains the conda channels/repositories and packages you need:     We begin by downloading the latest release from the Cotainr repository. In the example below we are downloading the latest version as of late 2023. Be sure to check for newer versions at the aforementioned repository. Look for the zip archive \"Assets\" section, and copy the link.    <pre><code>wget https://github.com/DeiC-HPC/cotainr/archive/refs/tags/2023.11.0.zip\n</code></pre>    You should now have a zip archive, which you can unzip with:    <pre><code>unzip 2023.11.0.zip\n</code></pre>    After this has been done, you should have a directory called <code>cotainr-2023.11.0</code>. We should now be able to launch Cotainr and access its commands from within this directory. Next, we will create a conda environment file, <code>conda_env.yml</code> that contains the conda channels/repositories and packages you need:  <p>Type <code>nano</code> and press <code>ENTER</code> (or use the editor of your choice), and enter the packages of your choice in the editor. In this example we will install <code>python=3.11.0</code> and <code>numpy=1.23.5</code>:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.11.0\n  - numpy=1.23.5\n</code></pre> <p>Instaling pip packages</p> <p>Cotainr does not allow the direct creation of a container from a pip requirements.txt file. Nevertheless, pip packages can be integrated into a conda environment. For instance, by updating <code>conda_env.yml</code> to include them.</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.11.0\n  - numpy=1.23.5\n  - pip\n  - pip:\n    - scipy==1.9.3\n</code></pre> <p>Save by pressing <code>CTRL + O</code> enter a file name, e.g. <code>conda_env.yml</code> and exit by pressing <code>CTRL + X</code>. Now you should have <code>conda_env.yml</code> in your directory. </p> <p>We can now build a container (Lets call it <code>conda_container.sif</code>) containing the conda environment specified in <code>conda_env.yml</code> with the following command:</p> <pre><code>srun /ceph/container/cotainr-2023.11.0/bin/cotainr build conda_container.sif --base-image=docker://ubuntu:22.04 --conda-env=conda_env.yml --accept-licenses\n</code></pre> <pre><code>srun cotainr-2023.11.0/bin/cotainr build conda_container.sif --base-image=docker://ubuntu:22.04 --conda-env=conda_env.yml --accept-licenses\n</code></pre> <p>Info</p> <p><code>--base-image=docker://ubuntu:22.04</code> is used because we have to use a base image in which bash is installed, like Ubuntu 22.04 image. </p> <p><code>--accept-licenses</code> is used to acknowledge the Miniforge license terms.</p> <p>After some time you should have <code>conda_container.sif</code> container image in your directory. </p> <p>You can access the conda image and run code using the dependencies you set up. Lets try to see if it works by printing the numpy version:</p> <pre><code>srun singularity exec conda_container.sif python3 -c \"import numpy; print(numpy.__version__)\"\n</code></pre> <p>The terminal should now print <code>1.23.5</code>.</p>"},{"location":"additional-guides/download-container-images/","title":"Download container images","text":"<p>You can download a large range of container images by visiting NVIDIA GPU Cloud (NGC) and check whether NVIDIA provides a container image with the application you need.</p> <p></p> <p>As an example, this could be TensorFlow. You can search on NGC and find TensorFlow. Here you can choose the desired version from the \"Copy image path\" dropdown menu:</p> <p></p> <p>This copies a link to the container image which we will use in the following example.</p> <p>We need to use Singularity to download the container image and in order to run Singularity, we must run it through the Slurm queueing system using the command <code>srun</code>. </p> <p>To download the container image to your directory paste the url to the container image like so:</p> <p><code>srun --mem 40G singularity pull docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code></p> <p>NOTE: The container image could take ~20 minutes to download. </p> <p>The above example consists of the following parts:</p> <ul> <li><code>srun</code>: the Slurm command which gets the following command executed on a compute node.</li> <li><code>mem</code>: a Slurm command that allows you allocate memory to your process, in this case 40GB of memory. A higher amount of memory than the default is needed specifically for this TensorFlow container image. Please see the Work-around for memory-consuming downloads section at the bottom of the page for a better way to avoid excessive memory requirements.</li> <li><code>singularity pull</code>: the Singularity command which downloads a specified container image.</li> <li><code>docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code>: this part of the command itself consists of two parts. <code>docker://</code> tells Singularity that we are downloading a Docker container image and Singularity automatically converts this to a Singularity container image upon download. <code>nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code> is the container image label copied from the NGC webpage which identifies the particular container image and version that we want.</li> </ul> <p>Once the <code>singularity pull</code> command has completed, you should have a file called <code>tensorflow_24.03-tf2-py3.sif</code> in your user directory (use the command <code>ls</code> to see the files in your current directory).</p>"},{"location":"additional-guides/download-container-images/#work-around-for-memory-consuming-downloads","title":"Work-around for memory-consuming downloads","text":"<p>Downloading some Singularity container images may require a large amount of memory to succeed, such as:</p> <pre><code>srun singularity pull docker://nvcr.io/nvidia/tensorflow:23.03-tf1-py3\n</code></pre> <p>If you simply run this command as-is, you are likely to experience an out-of-memory error during build of the container image. A work-around for this issue is to simply allocate more memory to your job using the <code>--mem</code> option for <code>srun</code> (it could easily require 40-50GB). This may cause your job to have to wait for a long time before it can start. </p> <p>There is, however, a better way to run Singularity to avoid the unreasonable memory requirement. Please follow these steps to use the <code>/tmp</code> partition of a compute node during build of your container image:</p> <ol> <li> <p>Start an interactive job for building your container image: <pre><code>srun --pty bash -l\n</code></pre> (You may add the <code>--nodelist</code> parameter to request a particular compute node as usual with <code>srun</code>.)</p> </li> <li> <p>Create a temporary directory for yourself to use during build of your container image: <pre><code>mkdir /tmp/`whoami`\n</code></pre> Take note of the back-tick characters in the above command; this is just to create a directory called <code>/tmp/username</code> if your username is <code>username</code>. You can call it something else instead, but it is important to create it under <code>/tmp</code>.</p> </li> <li> <p>Run Singularity to build your container image, using your new directory in <code>/tmp</code> for temporary data storage: <pre><code>SINGULARITY_TMPDIR=/tmp/`whoami` singularity pull docker://nvcr.io/nvidia/tensorflow:23.03-tf1-py3\n</code></pre> The <code>SINGULARITY_TMPDIR</code> variable should be set to whatever you named your temporary directory in step 2.</p> </li> <li> <p>After Singularity has finished building, delete your temporary directory: <pre><code>rm -r /tmp/`whoami`\n</code></pre></p> </li> <li> <p>Exit your interactive job: <pre><code>exit\n</code></pre></p> </li> </ol>"},{"location":"additional-guides/multiple-gpus-with-pytorch/","title":"Multiple GPUs with PyTorch","text":"<p>Distributed training across multiple GPUs is essential for accelerating deep learning tasks involving large datasets and complex models. PyTorch provides robust support for distributed computing through its <code>torch.distributed</code> package, facilitating efficient utilization of GPU resources using <code>torch.nn.parallel.DistributedDataParallel</code> (DDP). This guide presents a detailed explanation of how to implement and execute distributed training across multiple GPUs using PyTorch.</p>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#script-overview","title":"Script Overview","text":"<p>The provided Python script demonstrates how to perform distributed training across multiple GPUs using DDP in PyTorch. Let's break down each part of the script to understand its functionality and how it facilitates multi-GPU training.</p>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#part-1-imports-and-library-setup","title":"Part 1: Imports and Library Setup","text":"<p>Begin by importing necessary libraries and modules for GPU-accelerated deep learning tasks with PyTorch. The key module for distributed computing is <code>torch.distributed</code>.</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n</code></pre>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#part-2-distributed-setup","title":"Part 2: Distributed Setup","text":"<p>Next, we create a function called <code>setup</code> that initializes the distributed environment necessary for multi-GPU training:</p> <pre><code>def setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n</code></pre> <ul> <li><code>MASTER_ADDR</code> and <code>MASTER_PORT</code> are set to establish communication between different processes. This is crucial for coordinating distributed training across multiple GPUs.</li> <li><code>dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)</code> initializes the process group using the NCCL backend, which is optimized for efficient communication on NVIDIA GPUs.<ul> <li><code>rank</code> value is assigned to each proces to distinguish between processes.</li> <li><code>world_size</code> refers to the total number of processes that participate in the distributed training setup.</li> </ul> </li> <li><code>torch.cuda.set_device(rank)</code> ensures each process is assigned a specific GPU device based on its rank, enabling efficient GPU resource management.</li> </ul>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#part-3-cleanup-function","title":"Part 3: Cleanup Function","text":"<p>We then define a <code>cleanup()</code> function that ensures clean release of distributed training resources after completion, preventing resource leaks.</p> <pre><code>def cleanup():\n    dist.destroy_process_group()\n</code></pre>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#part-4-training-function","title":"Part 4: Training Function","text":"<p>Finally, we define a <code>train(rank, world_size)</code> function that orchestrates distributed training across multiple GPUs:</p> <pre><code>def train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#full-script","title":"Full script","text":"<pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"additional-guides/multiple-gpus-with-pytorch/#running-the-script","title":"Running the Script","text":"<p>To execute the multi-GPU training script we will use a Bash script (submit_job.sh):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=ddp_training\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=60G\n#SBATCH --time=02:00:00\n#SBATCH --output=ddp_training.out\n\n# Number of GPUs to allocate (adjust this value as needed)\nnum_gpus=4\n\n# Set the number of tasks and GPUs accordingly\n#SBATCH --ntasks=$num_gpus\n#SBATCH --gres=gpu:$num_gpus\n\n# Execute the job using Singularity\nsrun singularity exec --nv /ceph/container/pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=ddp_training\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=60G\n#SBATCH --time=02:00:00\n#SBATCH --output=ddp_training.out\n\n# Number of GPUs to allocate (adjust this value as needed)\nnum_gpus=4\n\n# Set the number of tasks and GPUs accordingly\n#SBATCH --ntasks=$num_gpus\n#SBATCH --gres=gpu:$num_gpus\n\n# Execute the job using Singularity\nsrun singularity exec --nv pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus\n</code></pre> <ul> <li><code>--job-name</code>: Specifies the name of the job.</li> <li><code>-partition</code>: Defines the partition or queue to submit the job to (l4 in this example).</li> <li><code>--cpus-per-task</code>: Specifies the number of CPUs allocated to each task.</li> <li><code>--mem</code>: Specifies the memory allocated to the job.</li> <li><code>--time</code>: Adjust these settings based on your specific resource requirements.</li> <li><code>num_gpus</code>: Modify this variable to specify the number of GPUs (--ntasks and --gres=gpu) allocated for your job.</li> <li><code>srun singularity exec --nv /ceph/container/pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus</code>: Executes the job inside the specified Singularity container (<code>pytorch_24.03-py3.sif</code>) with Python 3, running the <code>multi_gpu.py</code> script and passing <code>--world_size=$num_gpus</code> as an argument to specify the number of GPUs for distributed training.</li> </ul> <ul> <li><code>--job-name</code>: Specifies the name of the job.</li> <li><code>-partition</code>: Defines the partition or queue to submit the job to (l4 in this example).</li> <li><code>--cpus-per-task</code>: Specifies the number of CPUs allocated to each task.</li> <li><code>--mem</code>: Specifies the memory allocated to the job.</li> <li><code>--time</code>: Adjust these settings based on your specific resource requirements.</li> <li><code>num_gpus</code>: Modify this variable to specify the number of GPUs (--ntasks and --gres=gpu) allocated for your job.</li> <li><code>srun singularity exec --nv pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus</code>: Executes the job inside the specified Singularity container (<code>pytorch_24.03-py3.sif</code>) with Python 3, running the <code>multi_gpu.py</code> script and passing <code>--world_size=$num_gpus</code> as an argument to specify the number of GPUs for distributed training.</li> </ul>"},{"location":"additional-guides/run-a-bash-script/","title":"Run a bash script","text":"<p>In this guide, we will demonstrate how to submit a job to Slurm using a bash script. </p> <p>What is a bash script?</p> <p>A bash script is essentially a text file with a series of commands that you would normally type in the terminal. When executed, the script runs these commands in sequence. Bash scripts are used to automate repetitive tasks, manage system operations, and perform complex workflows.</p> <p>Let's create a bash script to submit a simple job that runs a Singularity container. This job will run a Python script inside the container.</p>"},{"location":"additional-guides/run-a-bash-script/#step-1-prepare-the-singularity-container","title":"Step 1: Prepare the Singularity Container","text":"Ensure you have a Singularity image (.sif file) ready. For this example, let's use the <code>tensorflow_24.03-tf2-py3.sif</code> container image from <code>/ceph/container</code>.       Ensure you have a Singularity image (.sif file) ready. For this example, we will use <code>tensorflow_24.03-tf2-py3.sif</code> container image."},{"location":"additional-guides/run-a-bash-script/#step-2-create-the-python-script","title":"Step 2: Create the Python Script","text":"<p>Create a simple Python script named hello.py:</p> <pre><code>print(\"Hello from within the Singularity container!\")\n</code></pre>"},{"location":"additional-guides/run-a-bash-script/#step-3-create-the-bash-script","title":"Step 3: Create the Bash Script","text":"<p>Create a bash script named run_job.sh:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=singularity_test\n#SBATCH --output=result_%j.out\n#SBATCH --error=error_%j.err\n#SBATCH --time=00:10:00\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=1G\n\nsingularity exec /ceph/container/tensorflow_24.03-tf2-py3.sif python hello.py\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=singularity_test\n#SBATCH --output=result_%j.out\n#SBATCH --error=error_%j.err\n#SBATCH --time=00:10:00\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=1G\n\nsingularity exec tensorflow_24.03-tf2-py3.sif python hello.py\n</code></pre> <p>Explanation of SBATCH Options:</p> <ul> <li><code>--job-name</code>: Name of the job (Optional).</li> <li><code>--output</code>: File where standard output will be written, with %j replaced by the job ID (Required).</li> <li><code>--error</code>: File where standard error will be written, with %j replaced by the job ID (Optional).</li> <li><code>--time</code>: Maximum run time (hh:mm) (Optional).</li> <li><code>--ntasks</code>: Number of tasks (Optional).</li> <li><code>--cpus-per-task</code>: Number of CPUs per task (Optional).</li> <li><code>--mem</code>: Memory per node (Optional).</li> </ul>"},{"location":"additional-guides/run-a-bash-script/#step-4-submit-the-job","title":"Step 4: Submit the Job","text":"<p>To submit the job, use the sbatch command:</p> <pre><code>sbatch run_job.sh\n</code></pre> <p>After the job gets submitted, you should be able to find a file called something like <code>result_x.out</code> with <code>Hello from within the Singularity container!</code> in it.</p>"},{"location":"additional-guides/running-a-container-in-interactive-mode/","title":"Running a container in interactive mode","text":"<p>You can launch a shell within a Singularity container, allowing you to interact with the container's environment. Use the <code>shell</code> command with the desired image as follows</p> <pre><code>srun --gres=gpu:1 --pty singularity shell --nv /ceph/container/tensorflow_24.03-tf2-py3.sif\n</code></pre> <pre><code>srun --gres=gpu:1 --pty singularity shell --nv tensorflow_24.03-tf2-py3.sif\n</code></pre> <p>The <code>--pty</code> creates a virtual interactive terminal for a command to run within.</p> <p>You now have shell access</p> <pre><code>Singularity&gt;\n</code></pre> <p>Lets try checking the Python version:</p> <pre><code>python3 --version\n</code></pre> <p>You can exit the interactive session with:</p> <pre><code>exit\n</code></pre>"},{"location":"additional-guides/setting-a-time-limit/","title":"Setting a time limit","text":"<p>Sometimes, jobs may get stuck or encounter unforeseen issues, causing them to run indefinitely. Setting a time limit ensures that such jobs are automatically terminated after a certain duration, preventing them from consuming resources unnecessarily.</p> <p>You can add a <code>--time</code> parameter to your Slurm command, e.g. <code>--time=08:00:00</code> to run a job for maximum 8 hours:</p> <p><pre><code>srun --time=08:00:00 hostname\n</code></pre> </p> Jobs can run no longer than 12 hours <p>     Every job submitted to AI-LAB is subject to a time limit of 12 hours. This limit is set to prevent a single user from monopolizing the entire cluster indefinitely. We are trying to ensure that all users receive an equal share of available resources.     </p>"},{"location":"applications/imagemagick/","title":"ImageMagick","text":"<p>On AI-LAB, we have a ready-to-use ImageMagick container image. This means that you can quickly access ImageMagick's functionality within the AI-LAB environment without needing to install or configure the software yourself. By utilizing the container image, you can efficiently work with images in your projects, transforming them as needed to suit your applications or experiments.</p> <p>First, lets get the path to the ImageMagick container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>To verify that everything is functioning as expected, let's use the \"mogrify\" tool to rotate some images. Begin by copying the following directory containing 100 cat images to your user directory:</p> <pre><code>scp /course/ailab-docs-files/cats ~\n</code></pre> <p>Next, create a folder to store the rotated images:</p> <pre><code>mkdir rotated_images\n</code></pre> <p>Finally, perform the image rotation by 90 degrees using the mogrify tool:</p> <pre><code>srun singularity exec /ceph/container/imagemagick_6.9.10-23.sif` mogrify -path rotated_images -rotate 90 cats/*.png\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"applications/matlab/","title":"MATLAB","text":"<p>On AI-LAB, we have a ready-to-use MATLAB container image. This means that you can quickly access MATLAB's functionality within the AI-LAB environment without needing to install or configure the software yourself. Lets try to batch process a MATLAB script:</p> <p>First, lets get the path to the MATLAB container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>Next, set the environment variable to specify the MATLAB license by running the following command:</p> <pre><code>source /ceph/course/claaudia/docs/set_matlab_license.sh\n</code></pre> <p>You can now process MATLAB scripts. To test if everything is working, copy the following script:</p> <pre><code>cp /ceph/course/claaudia/docs/matlab_script.m .\n</code></pre> <p>Then, batch process the script using the command:</p> <pre><code>srun singularity exec matlab_r2024a.sif matlab -batch \"run('script.m')\"\n</code></pre> <p>Note! The container image might be newer version at this time.</p> <p>If successful, the script should print <code>Hello World.</code></p>"},{"location":"applications/ollama-and-llm/","title":"Ollama and LLM","text":"<p>This guide will walk you through the process of running an Ollama container image on AI-LAB and using it to serve and run a Large Language Model (LLM) like Llam Next, you'll run the container in interactive mode. This allows you to interact with the container and execute commands within it. To do this, use the srun command with the --pty and --gres=gpu:1 options, which allocate a GPU for your session, and singularity shell --nv to open a shell within the container with GPU support enabled.</p> <pre><code>srun --pty --gres=gpu:1 singularity shell --nv /ceph/container/ollama_0.1.37.sif\n</code></pre> <p>Note! The container image might be newer version at this time.</p> <p>Inside the container, start the Ollama service in the background by adding <code>&amp;</code> to <code>ollama serve</code>. This will prepare the environment to serve LLM requests.</p> <pre><code>ollama serve &amp;\n</code></pre> <p>The ollama serve command will initialize the server that can handle requests for running models.</p> <p>When you get <code>Singularity&gt;</code> again, then the Ollama service running in the background. You can now run a Large Language Model such as Llama3 by running the following commands:</p> <pre><code>ollama run llama3\n</code></pre> <p>You should shortly after be able to interact with the LLM.</p> <p>This guide provides a basic framework for using Ollama on AI-LAB. Depending on your specific use case and requirements, you may need to adapt these instructions accordingly.</p>"},{"location":"applications/pytorch/","title":"PyTorch","text":"<p>On AI-LAB, we have a ready-to-use PyTorch container image. This means that you can quickly access PyTorch's functionality within the AI-LAB environment without needing to install or configure the software yourself.</p> <p>First, lets get the path to the PyTorch container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>You can run PyTorch scripts using Singularity to execute within the container. Below is an example of running a PyTorch script with 1 GPU allocated:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/pytorch_24.03-tf2-py3.sif python3 your_script.py\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"applications/pytorch/#checkpointing","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. Checkpointing in PyTorch can be used to save the state of your model at various points, enabling you to resume training from a specific epoch in case of interruptions or to fine-tune models from previously saved states. This guide demonstrates checkpoint implementation in PyTorch.</p>"},{"location":"applications/tensorflow/","title":"TensorFlow","text":"<p>On AI-LAB, we have a ready-to-use TensorFlow container image. This allows you to quickly leverage TensorFlow's functionality within the AI-LAB environment without needing to install or configure the software yourself.</p> <p>First, lets get the path to the TensorFlow container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>You can run TensorFlow scripts using Singularity to execute within the container. Below is an example of running a TensorFlow script with 1 GPU allocated:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 your_script.py\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"applications/tensorflow/#checkpointing","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. TensorFlow provides native support for checkpointing during model training, allowing you to save the model's weights at specific intervals. This guide demonstrates how to use the <code>ModelCheckpoint</code> callback to checkpoint with TensorFlow. </p>"},{"location":"courses/empty-for-now/","title":"Empty for now","text":"<p>This section is empty for now. If you are a lecturer, please have a look at Adding a course.</p>"},{"location":"getting-started/before-you-begin/","title":"Before you begin","text":"<p>Before diving into AI-LAB, ensure you have the necessary tools and knowledge for the best experience. Here's a brief overview:</p>"},{"location":"getting-started/before-you-begin/#request-access","title":"Request access","text":"<ul> <li>To request access to AI-LAB, apply here. Approval may currently take some time as AI-LAB is in beta. We will send you an email when you can access AI-LAB. If you don't receive access within 24 hours, please contact us</li> </ul>"},{"location":"getting-started/before-you-begin/#preperations","title":"Preperations","text":"<ul> <li>Ensure you are connected to the AAU network (including VPN)</li> <li>AI-LAB is accessed through the command-line interface. Need help getting started? Check our Terminal Basics guide</li> <li>For Windows users, use Windows PowerShell to follow our docs effectively. Alternatively, try installing OpenSSH or a Linux subsystem</li> </ul> <p>Please review our Guidelines, especially noting the following points:</p> <ul> <li>AI-LAB is not intended for working with confidential or sensitive data</li> <li>On August 1st of each year, all student data and user information will be automatically deleted from the AI-LAB platform if you haven't applied for extension</li> <li>Job durations are limited to a maximum of 12 hours</li> </ul> <p>With these preparations in place, lets get started </p>"},{"location":"getting-started/file-management/","title":"File management","text":"<p>You are now logged into AI-LAB and are in your user directory, which is located at <code>/ceph/home/&lt;domain&gt;/&lt;user&gt;</code>. You can confirm this by typing <code>pwd</code>. This directory is your private storage space where you can keep all your files. It is stored on a network file system, so you can access your files from any compute node within the platform.</p> <p>Here is the general file structure on AI-LAB:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> home user home directories <ul> <li> [domain] e.g student.aau.dk <ul> <li> [user] your user directory  </li> </ul> </li> </ul> </li> <li> project shared project directories </li> <li> course directory with course specific material </li> <li> container directory with ready-to-use applications </li> </ul> </li> </ul> <p>For a detailed overview of the AI-LAB storage system, click here.</p>"},{"location":"getting-started/file-management/#transfer-files-within-ai-lab","title":"Transfer files within AI-LAB","text":"<p>You can use the command <code>cp [source] [destination]</code> to copy files and <code>cp -r [source] [destination]</code> to copy folders to and from directories within AI-LAB. This will be useful when you need to retrieve applications or course materials later. For example:</p> <pre><code>cp /ceph/course/claaudia/docs/matlab_script.m .\n</code></pre> <p>Here, <code>/ceph/course/claaudia/docs/matlab_script.m</code> is the path to the file or folder you want to copy, and <code>.</code> is the path to where you want to copy it\u2014in this case, your user directory.</p>"},{"location":"getting-started/file-management/#transfer-files-between-your-local-computer-and-ai-lab","title":"Transfer files between your local computer and AI-LAB","text":"WindowsLinux/MacOS <p>You can transfer files between your local computer and AI-LAB using WinSCP. Other popular solutions are PuTTY and FileZilla. Alternatively, you can install OpenSSH to use the <code>scp</code> command, as shown for Linux/MacOS users.</p> <p>When you open WinSCP, you will be greeted by a Login modal. Follow the instructions in the image above to establish a connection to the server. </p> <p>You can now drag and drop files between your local computer and the AI-LAB platform.</p> <p>Info</p> <p>You might want to display hidden files in WinSCP (such as files starting with a dot on Linux systems). Go to Options \u2192 Preferences... \u2192 Panels and turn on \"Show hidden files\".</p> <p>You can transfer files between your local computer and AI-LAB using the command line utility <code>scp</code> from your local computer (note: You have to be logged out from AI-LAB to use <code>scp</code>).</p> <pre><code>scp some-file user@student.aau.dk@ailab-fe01.srv.aau.dk:~/some-dir\n</code></pre> <p>Replace <code>user@student.aau.dk</code> with your AAU email address.</p> <p>Here, <code>~</code> represents your user directory on AI-LAB and <code>/some-dir</code> a folder in your directory. </p> <p>To copy files from AI-LAB to your local computer, use:</p> <pre><code>scp user@student.aau.dk@ailab-fe01.srv.aau.dk:~/some-folder/some-subfolder/some-file .\n</code></pre> <p>Replace <code>user@student.aau.dk</code> with your AAU email address.</p> <p>Here, <code>.</code> represents the current directory on your local computer.</p> <p>Now that you know the basics of file transfer, lets proceed to learn how to get applications </p>"},{"location":"getting-started/getting-applications/","title":"Getting applications","text":"<p>To run applications on AI-LAB, you must use container images. On AI-LAB we use the container software, Singularity.</p> <p>What is a container image?</p> <p>A container image is a static, portable file that contains all the components needed to run a piece of software, including the code, runtime, system tools, libraries, and settings.</p>"},{"location":"getting-started/getting-applications/#pre-downloaded-container-images","title":"Pre-downloaded container images","text":"<p>The most straightforward method to acquire container images on AI-LAB is by accessing pre-downloaded container images stored in the <code>/ceph/container</code> directory. We aim to consistently update these container images to the latest versions.</p> <p>You can check which container images exist in the <code>/ceph/container</code> directory on AI-LAB with <code>ls</code>:</p> <pre><code>ls /ceph/container\n</code></pre> <p>To use the container images, you can either use them straight from the <code>/ceph/container</code> directory.</p> <p>Copying the container image</p> <p>If you need to modify the container image, make sure to copy the container image to your own directory. To copy the container, simply execute:</p> <pre><code>cp /ceph/container/tensorflow_24.03-tf2-py3.sif .\n</code></pre> <p>It may take a few minutes to copy. When you get your prompt back, the transfer has completed. Make sure by entering <code>ls</code> to see if <code>tensorflow_24.03-tf2-py3.sif</code> is in your directory.</p>"},{"location":"getting-started/getting-applications/#download-container-images","title":"Download container images","text":"<p>Alternatively, you can access a wide array of container images by visiting NVIDIA GPU Cloud (NGC) and exploring whether NVIDIA provides a container image for the application you require. Refer to our guide here for detailed instructions.</p>"},{"location":"getting-started/getting-applications/#build-your-own-container-images","title":"Build your own container images","text":"<p>You also have the flexibility to create your own container images tailored to your specific environment requirements. Refer to our guide on building your own container image.</p> <p></p> <p>Now that you know how to obtain applications, let's delve into running jobs </p>"},{"location":"getting-started/login/","title":"Login","text":"<p>To login you need to SSH connect to either of the two front-end nodes, <code>ailab-fe01</code> or <code>ailab-fe02</code>. </p> <p>Run the following command on a command-line interface on your local Windows (Windows PowerShell), macOS, or Linux computer:</p> <p><pre><code>ssh -l user@student.aau.dk ailab-fe01.srv.aau.dk\n</code></pre> or <pre><code>ssh -l user@student.aau.dk ailab-fe02.srv.aau.dk\n</code></pre></p> <p>Replace <code>user@student.aau.dk</code> with your AAU email address.</p> <p>Info</p> <p>The first time you connect, you will get a message like:</p> <pre><code>The authenticity of host 'ailab-fe01.srv.aau.dk (172.21.131.1300)' can't be established.\nED25519 key fingerprint is SHA256:xosJtOSfQyyW16c6RtpN8tAi/91XHCR3GxM9/KJEogg.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n</code></pre> <p>Please confirm by typing 'yes' to proceed with the connection.</p> <p>Enter your AAU password when prompted. </p> <p>When you can see <code>user@student.aau.dk@ailab-fe01:~$</code> you are succesfully logged in.</p> <p>You are now ready to proceed to learn about file management </p>"},{"location":"getting-started/next-steps/","title":"Next steps","text":"<p>To further explore and enhance your use of AI-LAB, we recommend to take a look at the following guides:</p> <ul> <li>Before running a job, learn how to check the queue to see how many jobs are ahead of you or review your own job status</li> <li>Discover how to run a container in interactive mode by using <code>shell</code> instead of <code>exec</code></li> <li>Submit a job to Slurm with a bash script, a text file containing commands you would typically enter in the terminal</li> <li>Learn how to monitor the resource status of compute nodes</li> <li>Implement checkpointing with Python, TensorFlow, and PyTorch to allow your jobs to resume from a saved state after interruptions</li> </ul>"},{"location":"getting-started/running-jobs/","title":"Running jobs","text":"<p>Before you start running jobs, it is important to be aware of the queueing system Slurm.</p>"},{"location":"getting-started/running-jobs/#slurm-queue-system","title":"Slurm queue system","text":"<p>Slurm is a job scheduling system and is used to allocate resources and manage user jobs on AI-LAB. Jobs on AI-LAB can only be run through Slurm. </p> <p>The primary method to run a job via Slurm is by utilizing the command <code>srun</code>. Let's try launching a job on a compute node:</p> <pre><code>srun hostname\n</code></pre> <p>Waiting in queue</p> <p>Upon execution, you might receive a notification indicating your job has been queued, awaiting resource availability:</p> <pre><code>srun: job X queued and waiting for resources\n</code></pre> <p>Once a compute node becomes available, you'll receive confirmation:</p> <pre><code>srun: job X has been allocated resources\n</code></pre> <p>Once a compute node becomes available the <code>hostname</code> command executes on the allocated compute node, revealing its identifier (e.g. <code>ailab-l4-01</code>).</p> <p>More Slurm commands</p> <p>You can find additional Slurm commands available to customize your job submissions, such as setting the time limit for a job, specifying the number of CPUs or GPUs, and more.</p>"},{"location":"getting-started/running-jobs/#executing-a-containerized-job-with-singularity","title":"Executing a containerized job with Singularity","text":"<p>To run a task within a container using Singularity, we need to add specific parameters to the Slurm command. </p> <p>As an example, let's try running <code>print('hello world')</code> using <code>Python3</code> within the <code>tensorflow_24.03-tf2-py3.sif</code> container image from <code>/ceph/container</code> directory.</p> <pre><code>srun singularity exec /ceph/container/tensorflow_24.03-tf2-py3.sif python3 -c \"print('hello world')\"\n</code></pre> <ul> <li><code>srun</code> is the Slurm command used to submit a job.</li> <li><code>singularity</code> is the command-line interface for interacting with Singularity.</li> <li><code>exec</code> is a sub-command that tells Singularity to execute a command inside the specified container.</li> <li><code>/ceph/container/tensorflow_24.03-tf2-py3.sif</code> is the path to the container image.</li> <li><code>python3 -c \"print('hello world')\"</code> is the task that singularity executes.</li> </ul> <p>While this execution proceeds smoothly, it's important to note that the command exclusively utilizes CPUs. The primary role of AI-LAB is to run software that utilises GPUs for computations. In order to run applications with a GPU you need to allocate a GPU to a job using Slurm. </p>"},{"location":"getting-started/running-jobs/#allocating-a-gpu-to-your-job","title":"Allocating a GPU to your job","text":"<p>You can allocate a GPU to a job using the <code>--gres=gpu</code> option for Slurm. Additionally, you need to add the <code>--nv</code> option to Singularity to enable NVIDIA drivers in the container.</p> <p>Let's try running a small Python script that performs a simple matrix multiplication of random data to benchmark TensorFlow computing speed with a GPU allocated:</p> <p>Copy <code>benchmark_tensorflow.py</code> from <code>/ceph/course/claaudia/docs</code> to your user directory:</p> <pre><code>cp /ceph/course/claaudia/docs/benchmark_tensorflow.py .\n</code></pre> <p>Lets try allocating 1 arbitrary available GPU to the job by adding <code>--gres=gpu:1</code>:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <p>Note that the above example allocate 1 GPU to the job. It is possible to allocate more, for example <code>--gres=gpu:2</code> for two GPUs. Software for computing on GPU is not necessarily able to utilise more than one GPU at a time. It is your responsibility to ensure that the software you run can indeed utilise as many GPUs as you allocate. It is not allowed to allocate more GPUs than your job can utilise. Here is an example of a PyTorch script that can handle multiple GPUs. </p> <p> Congratulations! </p> <p>You've mastered the fundamentals of AI-LAB. Ready to take the next steps? </p>"},{"location":"help-and-resources/glossery/","title":"Glossery","text":""},{"location":"help-and-resources/glossery/#hpc","title":"HPC","text":"<p>High-performance computing (HPC) uses powerful resources to perform complex, data-intensive tasks beyond a single computer's capacity. HPC systems include multiple processors, large memory, and specialized networking for rapid data exchange. Researchers can simulate, model, and analyse data at unprecedented speed and scale.</p>"},{"location":"help-and-resources/glossery/#deep-learning","title":"Deep learning","text":"<p>The AI Cloud is a facility consisting of several servers designed to be ideal for training deep learning algorithms. Deep learning is in many cases branded as artificial intelligence (AI) - hence the name AI Cloud. This also makes the facility good for a wide range of computationally intensive work such as numerical simulations and high-performance data analysis (HPDA). See \"Overview\" in the menu above for more details on what the AI Cloud consists of.</p>"},{"location":"help-and-resources/glossery/#parallel-computing","title":"Parallel Computing","text":"<p>Parallel computing refers to the simultaneous execution of multiple tasks or parts of a single task across multiple processing units, such as CPUs or GPUs. This approach significantly accelerates computational tasks by dividing the workload among several processors, thereby reducing overall processing time.</p>"},{"location":"help-and-resources/glossery/#front-end-node","title":"Front-end node","text":"<p>The front-end node is used for logging into the platform, accessing your files, and starting jobs on the compute nodes. The front-end node is a relatively small server which is not meant for performing heavy computations; only light-weight operations such as transferring files to and from AI-LAB and defining and launching job scripts.</p>"},{"location":"help-and-resources/glossery/#computing-cluster","title":"Computing cluster","text":"<p>A computing cluster is a collection of interconnected computers (compute nodes) that work together as a single, integrated computing resource. This setup is designed to handle large computational tasks more efficiently than a single computer could. Clusters are used for tasks that require high performance and availability, such as scientific simulations, data analysis, and large-scale web services.</p>"},{"location":"help-and-resources/glossery/#compute-nodes","title":"Compute nodes","text":"<p>Compute Nodes are the individual computers within the Computing cluster that perform the actual computational work. Each compute node is a separate computer, equipped with its own processors (CPUs), memory (RAM), and GPUs for specialized computations. Compute nodes are networked together and run a unified operating system and software environment. Compute nodes are tasked with executing the computational jobs submitted by users. In AI-LAB, users don't interact directly with compute nodes. Instead, they submit jobs through the job scheduler Slurm, which then allocates the necessary resources and runs the job on the compute nodes.</p>"},{"location":"help-and-resources/glossery/#slurm","title":"Slurm","text":"<p>The Slurm queue system is AI-LABs job scheduling and management tool commonly used in HPC environments. It efficiently allocates computing resources by prioritizing and scheduling jobs submitted by users based on their requirements and available resources. Through Slurm, users can submit their computational tasks to a centralized queue, allowing for fair resource distribution and optimal utilization of the HPC system.</p>"},{"location":"help-and-resources/glossery/#image","title":"Image","text":"<p>An image is a static, portable file that contains all the components needed to run a piece of software, including the code, runtime, system tools, libraries, and settings. It serves as a blueprint for creating containers.</p>"},{"location":"help-and-resources/glossery/#container","title":"Container","text":"<p>A container is a runtime instance of an image that is executed and managed by Singularity. Containers provide an isolated environment to run applications, ensuring consistency and portability across different systems.</p>"},{"location":"help-and-resources/guidelines/","title":"Guidelines","text":""},{"location":"help-and-resources/guidelines/#data-deletion-and-extension-policies","title":"Data deletion and extension policies","text":"<p>Every year at 1. August, all student data and user information will be automatically removed from the AI-LAB platform. You will receive email notifications 2 months, 1 month, 14 days, and 2 day prior to the deletion date. It is important to ensure that you transfer any desired files from AI-LAB to your local computer before the deletion date.</p> <p>Extension request:</p> <p>Should you wish to keep your data on AI-LAB and use the platform for another year, you can submit an extension request through the application form for AI-LAB. This will extend your access until August 1st of the following year.</p>"},{"location":"help-and-resources/guidelines/#not-for-confidential-or-sensitive-data","title":"Not for confidential or sensitive data","text":"<p>In AI-LAB you are only allowed to work with public or internal information according to AAU\u2019s data classification model (classified as levels 0 and 1, respectively).</p> <p>If you would like to work with confidential or sensitive data (classified as levels 2 and 3), then we support another HPC platform called UCloud.</p>"},{"location":"help-and-resources/guidelines/#scheduled-maintenance","title":"Scheduled maintenance","text":"<p>On specific dates, scheduled maintenance will be conducted on AI-LAB. The routine maintenance will occur between 00:01 and 23:59. AI-LAB will be unavailable throughout most of that day. You can still submit new jobs until the beginning of the service window. For jobs that may exceed the service window, please ensure to set a maximum runtime using the parameter <code>--time</code> that concludes before 23:59 the day preceding the service window. Read more about the <code>--time</code> parameter here. Otherwise, these jobs will not be able to start until after the maintenance period. You will receive email notifications 1 month, 14 days, and 1 day prior to the scheduled maintenance window.</p>"},{"location":"help-and-resources/guidelines/#clean-up-after-use","title":"Clean up after use","text":"<p>AI-LAB encourages responsible usage, which includes cleaning up your user directory for files that are no longer needed. You can use <code>rm [file_name]</code> to remove a file and <code>rm -r [directory_name]</code> to remove a directory and its contents.</p> <p>Before deleting files, remember that you can transfer files from your AI-LAB directory to your local computer.</p>"},{"location":"help-and-resources/guidelines/#data-management-best-practices","title":"Data Management best practices","text":"<p>Effective data management is crucial for maximizing the value of your research and ensuring its integrity. Organize your data in a clear and structured manner, labeling files and directories appropriately. Regularly back up your data to prevent loss in case of unexpected events. Additionally, adhere to any data sharing and privacy regulations applicable to your field. Get more guidance about data management here.</p>"},{"location":"help-and-resources/guidelines/#jobs-can-run-no-longer-than-12-hours","title":"Jobs can run no longer than 12 hours","text":"<p>Every job submitted to AI-LAB is subject to a time limit of 12 hours. This limit is set to prevent a single user from monopolizing the entire cluster indefinitely. We are trying to ensure that all users receive an equal share of available resources. </p>"},{"location":"help-and-resources/guidelines/#not-intended-for-cpu-processing","title":"Not intended for CPU processing","text":"<p>The platform excels in tasks requiring parallel processing capabilities, such as training deep learning models, image and video analysis, and other GPU-accelerated computational work. However, it's not intended for applications that only need CPU processing.</p>"},{"location":"help-and-resources/guidelines/#allocating-the-right-amount-of-resources","title":"Allocating the right amount of resources","text":"<p>Please be mindful of your allocations and refrain from allocating many resources without knowing/testing/verifying that you indeed can utilise all of the allocated resources. </p> <p>Please be mindful and de-allocate the resources when you are no longer using them. This enables other users to run their jobs.</p>"},{"location":"help-and-resources/guidelines/#focus-on-data-processing-not-storage","title":"Focus on data processing, not storage","text":"<p>AI-LAB is designed primarily for data processing, not storage. Our High-Performance Computing (HPC) platform supports complex data analysis and simulation tasks efficiently. This focus ensures our resources are distributed optimally among users.</p>"},{"location":"help-and-resources/known-issues/","title":"Known issues","text":""},{"location":"help-and-resources/known-issues/#why-do-i-get-r-error-when-running-my-python-script","title":"Why do I get <code>\\r</code> error when running my Python script?","text":"<p>If you encounter an error message like: <code>/usr/bin/env python3/r: bad interpreter: No such file or directory</code> while running a .py file, it might be because the file was edited on your local Windows computer before moving it to AI-LAB. Line endings often get converted when files are moved between Linux and Windows. This conversion is a frequent issue as Linux and Unix-like systems use <code>\\n</code> for line breaks, whereas Windows uses <code>\\r\\n</code> (CRLF, Carriage Return + Line Feed). </p> <p>Solution: In code editors such as VS Code or PyCharm, you can switch between LF (Linux endings) and CRLF (Windows endings) from the right-hand side of the status bar at the bottom of the window. Therefore, use LF endings if you wish to move a file to AI-LAB.</p>"},{"location":"help-and-resources/known-issues/#why-do-i-get-error-generating-job-credential-when-running-a-job","title":"Why do I get <code>Error generating job credential</code> when running a job?","text":"<p>Sometimes there are challenges with Active Directory (AD) at Aalborg University where AD fails to translate UIDs to people's usernames. Consequently, Slurm may encounter authentication issues, preventing you from running a job, and you may notice the job hanging when you run <code>sinfo</code>.</p> <p>Solution: Often, the problem resolves itself after some time (~20 minutes), and you will be able to run jobs again. You can also try running the <code>id</code> command to translate the username to UID, which usually gets cached and starts working after a while.</p>"},{"location":"help-and-resources/support/","title":"Support","text":"<p>The platform offers support through the CLAAUDIA team. We can help you diagnose and resolve general issues you might encounter while using AI-LAB. For all questions and requests related to the availability, use and troubleshooting of AI-LAB, please contact us through the AAU service portal and refer to CLAAUDIA in the subject. </p> <p>A good practice for asking a question</p> <p>To ensure optimal technical assistance, we advise you follow these recommended practices when submitting questions and requests:</p> <ol> <li>Use a detailed subject line. Doing so facilitates the quick identification of the problem and connects it with similar incidents previously reported by other users.</li> <li>Clarify what you have done so far and which operating system you use. Include specifics like which applications you are using. This detail aids in accurately recreating your environment to better understand the issue.</li> <li>Explain the issue and what you intended to achieve. Provide a comprehensive description of the issue, noting what has worked up to that point and the steps you've taken in an attempt to resolve it.</li> </ol>"},{"location":"help-and-resources/terminal-basics/","title":"Terminal basics","text":"<p>The following commands provide a solid foundation for navigating and working within a Linux terminal environment, particularly in the context of AI-LAB. Familiarize yourself with these commands to enhance your productivity and efficiency when using the platform. You can also look at this basic course to the shell at: https://linuxjourney.com/lesson/the-shell.</p> <p></p>"},{"location":"help-and-resources/terminal-basics/#navigation-commands","title":"Navigation Commands:","text":"<ul> <li><code>pwd</code>: Displays the current directory path.</li> <li><code>ls</code>: Shows the files and directories in the current location.</li> <li><code>cd [directory_name]</code>: Change to a directory within the current directory.</li> <li><code>cd /path/to/directory</code>: Change to an absolute directory path.</li> <li><code>cd ..</code>: Move up one directory level.</li> <li><code>cd ~</code>: Move to the home directory.</li> <li><code>cd -</code>: Return to the previous directory.</li> </ul>"},{"location":"help-and-resources/terminal-basics/#file-management-commands","title":"File Management Commands:","text":"<ul> <li><code>mkdir [directory_name]</code>: Create a directory with a specific name.</li> <li><code>rmdir [directory_name]</code>: Remove a directory.</li> <li><code>touch [file_name]</code>: Create a file with a specific name.</li> <li><code>cp [source] [destination]</code>: Copy a file or directory from the source to the destination.</li> <li><code>mv [source] [destination]</code>: Move a file or directory to a new location or rename it.</li> <li><code>rm [file_name]</code>: Remove a file.</li> <li><code>rm -r [directory_name]</code>: Remove a directory and its contents recursively.</li> </ul>"},{"location":"help-and-resources/terminal-basics/#text-editing-commands","title":"Text Editing Commands:","text":"<ul> <li><code>nano [file_name]</code>: Open a file for editing.<ul> <li><code>Ctrl + O</code>: Saving a File.</li> <li><code>Ctrl + X</code>: Exit Nano.</li> </ul> </li> <li><code>vim [file_name]</code>: Open a file for editing.<ul> <li><code>:q</code>: Exit Vim.</li> <li><code>:wq</code>: Exit and save Vim.</li> <li><code>i</code>: Enter insert mode, where you can type to insert or edit text. Press Esc to exit insert mode.</li> </ul> </li> </ul>"},{"location":"help-and-resources/terminal-basics/#other-useful-commands","title":"Other Useful Commands:","text":"<ul> <li><code>cat [file_name]</code>: Display the contents of a file.</li> <li><code>grep [pattern] [file_name]</code>: Search for a specific pattern within a file.</li> <li><code>man [command_name]</code>: Access the manual pages for a specific command.</li> <li><code>history</code>: Display command history.</li> </ul>"},{"location":"help-and-resources/for-lecturers/adding-a-course/","title":"Adding a course","text":"<p>You are invited to design your own course for AI-LAB. You can create your own pages within the documentation and upload course materials directly to the AI-LAB server.</p>"},{"location":"help-and-resources/for-lecturers/adding-a-course/#how-to-add-a-course-to-the-documentation","title":"How to add a course to the documentation","text":"<p>Follow these steps to create a new course:</p> <ol> <li>To be able to contribute you will need a GitHub account.</li> <li>Start by forking the repository to your GitHub account from here: https://github.com/aau-claaudia/ailab-docs/fork.</li> <li>Go into your forked repository and in the <code>/docs/courses</code> directory, create a new folder named after your course. This folder will contain your <code>.md</code> files, which form the basis of your course content.</li> </ol> <p>Info</p> <ul> <li>We use Markdown format and Material for MkDocs for styling. </li> <li>The easiest way to get started with your page is by using this online editor: https://md.sigma2.no/new.</li> <li>You can also install Material for MkDocs by following this getting started guide.</li> <li>For design tips, refer to our page design guide.</li> <li>Your course series may include multiple files, e.g., <code>tensorflow-course-1.md</code>, <code>tensorflow-course-2.md</code>, etc.</li> </ul> <ol> <li>Once you have made the necessary changes, submit a pull request to the main repository.</li> <li>We will review your changes and, if everything is in order, merge your pull request.</li> </ol>"},{"location":"help-and-resources/for-lecturers/adding-a-course/#adding-container-image-files-to-ai-lab","title":"Adding container image files to AI-LAB","text":"<p>You can add your own container image files to the <code>/ceph/container</code> directory on AI-LAB. Simply <code>cp</code> the container from your own directory to the <code>/ceph/container</code> or use <code>scp</code> if you want to transfer it from your local computer. Take a look at File management for more details. </p> <p>We also have guides on how to download container images and how to build your own container image.</p>"},{"location":"help-and-resources/for-lecturers/adding-a-course/#adding-course-material-to-ai-lab","title":"Adding course material to AI-LAB","text":"<p>Similar to adding container image files, you can add files to the <code>/ceph/course</code> directory on AI-LAB. It could be datasets or scripts, but also container images. Please make a directory (<code>mkdir [name]</code>) that you can store your files in.</p>"},{"location":"help-and-resources/for-lecturers/page-design-guide/","title":"Page design guide","text":"<p>This is a basic overview of which features you can use to design a MkDocs page. You can find more information at https://squidfunk.github.io/mkdocs-material/reference/.</p> Normal paragraph<pre><code>You write normal paragraph text just by typing like this. \n</code></pre> <p>Preview  You write normal paragraph text just by typing like this. </p> Headings<pre><code>You can create headings by placing a # before the text like so:. \n# Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n</code></pre> <p>Preview </p> Inserting links<pre><code>You can insert links by:\n\nI want to insert a link [here](https://www.researcher.aau.dk/contact/claaudia)\n</code></pre> <p>Preview  I want to insert a link here</p> Code in paragrapgh<pre><code>You use backticks to `write code in text`.\n</code></pre> <p>Preview  You use backticks to <code>write code in text</code>.</p> Console codeblocks<pre><code> You can also create a console codeblock like so:\n\n ```console\n ssh -l xxxxxx@student.aau.dk ai-fe02.srv.aau.dk\n ```\n</code></pre> <p>Preview <pre><code>ssh -l xxxxxx@student.aau.dk ai-fe02.srv.aau.dk\n</code></pre></p> Python codeblocks<pre><code> You can also create a Python codeblock like so:\n\n ```py\n import tensorflow as tf\n for i in range(len(100)):\n    print(i)\n ```\n</code></pre> <p>Preview <pre><code>import tensorflow as tf\n\nfor i in range(len(100)):\n    print(i)\n</code></pre></p> Call-outs<pre><code>You can make call-outs/admonitions like so:\n\n!!! info \"This is the title\"\n    This is the content\n</code></pre> <p>Preview</p> <p>This is the title</p> <p>This is the content</p> Data tables<pre><code>You can also create data tables like this:\n\n| Method      | Description     |\n| ----------- | --------------- |\n| `GET`       | Fetch resource  |\n| `PUT`       | Update resource |\n| `DELETE`    | Delete resource |\n</code></pre> <p>Preview </p> Method Description <code>GET</code> Fetch resource <code>PUT</code> Update resource <code>DELETE</code> Delete resource Custom HTML/CSS<pre><code>&lt;div&gt;\n    &lt;p&gt;\n        You can paste your own custom HTML/CSS as you would in a normal .html file\n    &lt;/p&gt;\n&lt;/div&gt;\n</code></pre> <p>Preview </p> <p>         You can paste your own custom HTML/CSS as you would in a normal .html file     </p> Inserting images<pre><code>You can insert images from urls or by uploading images to \"/assets/img/\":\n\n![Image of CLAAUDIA Logo](../../assets/img/claaudia-logo.pngg)\n</code></pre> <p>Preview </p>"},{"location":"help-and-resources/for-lecturers/page-design-guide/#heading-1","title":"Heading 1","text":""},{"location":"help-and-resources/for-lecturers/page-design-guide/#heading-2","title":"Heading 2","text":""},{"location":"help-and-resources/for-lecturers/page-design-guide/#heading-3","title":"Heading 3","text":""},{"location":"help-and-resources/for-lecturers/page-design-guide/#heading-4","title":"Heading 4","text":""},{"location":"system-overview/hardware/","title":"Hardware","text":"<p>The AI-LAB platform is built around several key components, including two front-end nodes for managing tasks and code, and 11 compute nodes equipped with diverse hardware options.</p> <p>In this overview, you will find a description of each major component of AI-LAB. Below, is a diagram illustrating the architecture of the AI-LAB platform.</p> <pre><code>flowchart LR\n  subgraph id1[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n  direction TB\n  A[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;ailab-l4-[01-11]&lt;/span&gt;\"]\n  end\n\n  subgraph id2[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;AI-LAB&lt;/p&gt;]\n  direction TB\n  subgraph id3[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Front-end nodes&lt;/p&gt;]\n    direction TB\n    G[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;ailab-fe[01-02]&lt;/span&gt;\"]\n    end\n  id3 --&gt; id1 \n\n  subgraph id4[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;File storage&lt;/p&gt;]\n    direction TB\n    E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Ceph&lt;/span&gt;\"]\n    end\n\n  id1 &amp; id3 &lt;--&gt; id4\n  end\n\n  F[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]-- SSH --&gt; id3\n</code></pre>"},{"location":"system-overview/hardware/#front-end-nodes","title":"Front-end nodes","text":"<p>You start by logging into a front-end node, either <code>ailab-fe01</code> or <code>ailab-fe02</code>. These nodes act as the gateway to the HPC system. Here, you can manage files, write and edit code, and prepare your computational tasks. It is important to note that front-end nodes are not intended for heavy computations; they are optimized for task preparation and interaction with the HPC environment.</p>"},{"location":"system-overview/hardware/#compute-nodes","title":"Compute nodes","text":"<p>AI-LAB currently include the following compute nodes:</p> Node name CPU model Number of CPUs Number of cores Number of GPUs GPU Model Total Memory (GB) ailab-l4-[01-11] AMD EPYC 7543 32-Core 128 64 8 NVIDIA L4 500"},{"location":"system-overview/software/","title":"Software","text":"<p>AI-LAB is based on Ubuntu Linux as its operating system. In practice, working on AI-LAB primarily takes place via a command-line interface.</p> <p>AI-LAB leverages two primary software components: Slurm and Singularity. Understanding these tools and how they work together is crucial for efficiently utilizing the AI-LAB platform.</p>"},{"location":"system-overview/software/#slurm","title":"Slurm","text":"<p>Slurm is a powerful and highly configurable workload manager used for scheduling and managing compute jobs on AI-LAB. It provides essential features such as:</p> <ul> <li>Job Scheduling: Allocating resources to jobs based on user requests and system policies.</li> <li>Resource Management: Tracking and managing compute resources, ensuring optimal utilization.</li> <li>Queue Management: Organizing jobs into queues, prioritizing and executing them based on policies and resource availability.</li> </ul> <p>On AI-LAB, Slurm is responsible for managing the allocation and scheduling of compute resources, ensuring that user jobs are executed efficiently and fairly.</p> <pre><code>flowchart LR\n  B[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Front-end node&lt;/span&gt;\"]\n\n  C[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 4&lt;/span&gt;\"]\n\n  subgraph slurm[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;Slurm queue&lt;/p&gt;]\n    direction LR\n    D1[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 4&lt;/span&gt;\"]\n    D2[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 3&lt;/span&gt;\"]\n    D3[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 2&lt;/span&gt;\"]\n    D1 -.- D2 -.- D3\n    end\n\n  subgraph cluster[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n    direction LR\n\n    E1[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 1&lt;/span&gt;\"]\n    E2[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;ailab-l4-01&lt;/span&gt;\"]\n\n    E1 --&gt; E2\n    end\n\n  B --&gt; C --&gt; slurm --&gt; cluster\n\n  style D1 stroke-dasharray: 5 5\n</code></pre>"},{"location":"system-overview/software/#singularity","title":"Singularity","text":"<p>Singularity is a container platform designed for running applications on AI-LAB. Containers are lightweight, portable, and reproducible environments that bundle an application's code, libraries, and dependencies. Key features of Singularity include:</p> <ul> <li>Compatibility: Running containers with high-performance computing workloads without requiring root privileges.</li> <li>Portability: Enabling the same container to run on different systems without modification.</li> <li>Integration with HPC Systems: Designed to work seamlessly with HPC job schedulers like Slurm.</li> </ul> <p></p>"},{"location":"system-overview/software/#pre-downloaded-containers-on-ai-lab","title":"Pre-Downloaded Containers on AI-LAB","text":"<p>AI-LAB provides a variety of pre-downloaded containers to help users get started quickly. These containers are stored in the <code>/ceph/container</code> directory. The list of available containers is periodically updated, and users can propose new containers by contacting the support team. Currently available container images includes:</p> <ul> <li>PyTorch (CPU/GPU)</li> <li>TensorFlow (CPU/GPU)</li> <li>ImageMagick (CPU)</li> <li>MATLAB (CPU/GPU)</li> </ul>"},{"location":"system-overview/software/#interconnection-of-slurm-and-singularity","title":"Interconnection of Slurm and Singularity","text":"<p>On AI-LAB, Slurm and Singularity work together. Slurm handles the job scheduling and resource allocation, while Singularity ensures that the specified container environment is instantiated and the application runs with all its dependencies.</p> <pre><code>flowchart LR\n  A[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]\n  B[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Front-end node&lt;/span&gt;\"]\n  C[\"&lt;span&gt;&lt;img src=\"/assets/img/container.svg\" width='25' height='25'&gt;Singularity container job&lt;/span&gt;\"]\n  D[\"&lt;span&gt;&lt;img src=\"/assets/img/queue.svg\" width='25' height='25'&gt;Slurm&lt;/span&gt;\"]\n  E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Compute node&lt;/span&gt;\"]\n\n  A-- SSH --&gt; B --&gt; C --&gt; D --&gt; E-- Result --&gt; B\n\n  style C stroke-dasharray: 5 5\n  style D stroke-dasharray: 5 5\n</code></pre>"},{"location":"system-overview/storage/","title":"Storage","text":"<p>AI-LAB utilizes Ceph as its storage solution, providing a robust and scalable file system for your data needs. Your files are organized within the Ceph file system hierarchy, ensuring efficient access and management across the entire platform.</p>"},{"location":"system-overview/storage/#user-directory","title":"User Directory","text":"<p>Your user directory serves as the primary location for storing personal files and data. It is structured within the Ceph file system as follows:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> home user home directories <ul> <li> [domain] e.g student.aau.dk <ul> <li> [user] your user directory</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Here, [domain] represents your domain or institution (e.g., student.aau.dk), and [user] denotes your unique username on the platform. Any files you store within your user directory are private.</p> <p>Storage quota</p> <p>When users log in to AI-LAB for the first time, a user directory is created for them. These directories are allocated 1 TB of storage by default. When you log in to the platform, you can see your storage usage of the user directory at the very top line:</p> <pre><code>Current quota usage: 181GiB / 1.0TiB\nWelcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-169-generic x86_64)\n\n* Documentation:  https://help.ubuntu.com\n* Management:     https://landscape.canonical.com\n* Support:        https://ubuntu.com/pro\n\nSystem information as of Fri Mar 15 11:09:21 CET 2024\n</code></pre>"},{"location":"system-overview/storage/#shared-project-directories","title":"Shared Project Directories","text":"<p>AI-LAB fosters collaborative work through shared project directories. These directories enable multiple users to collaborate on projects by providing a centralized space for data sharing and collaboration. Shared project directories are organized under the project directory within the Ceph file system:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> project shared project directories <ul> <li> project_X             </li> </ul> </li> </ul> </li> </ul> <p>TODO: Guide on how to utilize this</p>"},{"location":"system-overview/storage/#course-materials","title":"Course Materials","text":"<p>To support educational activities, AI-LAB hosts course-specific materials within dedicated directories. These materials include lecture notes, assignments, datasets, and any resources relevant to the course curriculum. Course directories are structured under the course directory within the Ceph file system:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> course directory with course specific material <ul> <li> Course 1. Introduction to TensorFLow                 <ul> <li> Images</li> <li> tensorflow.sif</li> </ul> </li> <li> Course 2. ...             </li> </ul> </li> </ul> </li> </ul> <p>Students and instructors can access course materials effortlessly, enhancing the learning experience and facilitating hands-on exercises.</p>"},{"location":"system-overview/storage/#ready-to-use-applications","title":"Ready-to-Use Applications","text":"<p>For convenience and efficiency, AI-LAB offers a collection of ready-to-use applications packaged as container images that can easily be copied to your user directoty. We aim to consistently update these images to the latest versions.</p> <ul> <li> /ceph         <ul> <li> container directory with ready-to-use applications <ul> <li> tensorflow.sif</li> <li> pytorch.sif</li> <li> ...sif</li> </ul> </li> </ul> </li> </ul> <p>If you have specific container image requests, we welcome your input. Please reach out to us via the AAU service portal and include \"CLAAUDIA\" and \"AI-LAB\" in the subject line.</p>"}]}